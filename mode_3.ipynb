{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4fa09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import lru_cache\n",
    "import os\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e3e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 400\n",
    "num_points = 50\n",
    "hidden_dim = 128\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e116d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d2b43acb90>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pris = np.loadtxt(os.path.expanduser('~/Downloads/transmissions/size_10/size_10_pris.csv'), delimiter=',')\n",
    "plt.plot(pris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e594169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10\n",
    "@lru_cache(maxsize=1024)\n",
    "def configs(conc):\n",
    "    df = {}\n",
    "    for x in range(5000):\n",
    "        path = os.path.expanduser(f'~/Downloads/transmissions/size_10/lead_size_10_conc_{conc}_config_{x}.csv')\n",
    "        new_data = np.loadtxt(path, delimiter=',',skiprows=1)[:,1]\n",
    "        df[x] = new_data\n",
    "    df = pd.DataFrame(df)\n",
    "#    df.index = np.arange(0, 4, 0.01)\n",
    "    return df.clip(upper=size)\n",
    "\n",
    "\n",
    "DEVICE_COMBS = {}\n",
    "\n",
    "@lru_cache(maxsize=1024)\n",
    "def chosen_for_config(n, size, config):\n",
    "    width = int(size); n = int(n); cfg = int(config)\n",
    "    if width not in DEVICE_COMBS:\n",
    "        DEVICE_COMBS[width] = np.array([(i, j) for i in range(100) for j in range(width)], dtype=int)\n",
    "    device_combs = DEVICE_COMBS[width]\n",
    "    rng = np.random.RandomState(cfg)\n",
    "    chosen_indices = rng.choice(len(device_combs), size=n, replace=False)\n",
    "    return device_combs[chosen_indices]\n",
    "\n",
    "\n",
    "def possible_combs(n, width):\n",
    "    def combs_for_seed(x):\n",
    "        return chosen_for_config(n, width, x)\n",
    "    return combs_for_seed\n",
    "\n",
    "@lru_cache(maxsize=1024)\n",
    "def distance_matrix(conc,config):\n",
    "    imps  = possible_combs(conc, size)\n",
    "    item = imps(config)\n",
    "    #print(np.diag(item[:,1]))\n",
    "    x = np.stack((size - item[:,1],item[:,1]), axis=1)\n",
    "    return squareform(pdist(item, metric='euclidean')) + np.diag(x.min(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0fb476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    x = []\n",
    "    y = []\n",
    "    for conc in np.arange(7,50,2):\n",
    "        print(f\"Processing concentration: {conc}\")\n",
    "        for config in range(5000):\n",
    "            dist_mat = 0 *np.eye(50)\n",
    "            dist_mat[:conc,:conc] +=  distance_matrix(conc, config)\n",
    "            path = os.path.expanduser(f'~/Downloads/transmissions/size_10/lead_size_10_conc_{conc}_config_{config}.csv')\n",
    "            new_data = np.loadtxt(path, delimiter=',',skiprows=1)[:,1]\n",
    "            #arr = configs(conc).index,configs(conc)[config]\n",
    "            #arr = np.array(arr).T\n",
    "            y.append(dist_mat)\n",
    "            x.append(np.clip(new_data, 0, pris))\n",
    "\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    print(f\"Shape of x: {x.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "    return x,y\n",
    "\n",
    "x,y = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab4b1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating manifest file...\n",
      "Done! Created manifest.csv with 110000 entries.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating manifest file...\")\n",
    "\n",
    "# This will store the info for each s#ample\n",
    "manifest_data = []\n",
    "# Define the root directory where files are stored\n",
    "root_dir = os.path.expanduser('~/Downloads/transmissions/size_10/')\n",
    "\n",
    "# Use the same loops as your original script\n",
    "for conc in np.arange(7, 50, 2):\n",
    "    for config in range(5000):\n",
    "        # We just construct the path, we don't load the file here\n",
    "        path = f'lead_size_10_conc_{conc}_config_{config}.csv'\n",
    "        full_path = os.path.join(root_dir, path)\n",
    "\n",
    "        # Check if the file actually exists before adding it to the manifest\n",
    "        if os.path.exists(full_path):\n",
    "            manifest_data.append({\n",
    "                \"concentration\": conc,\n",
    "                \"config_id\": config,\n",
    "                \"filepath\": path  # Store the relative path\n",
    "            })\n",
    "\n",
    "# Convert the list of data into a pandas DataFrame\n",
    "manifest_df = pd.DataFrame(manifest_data)\n",
    "\n",
    "# Save the manifest to a CSV file\n",
    "manifest_df.to_csv(\"manifest.csv\", index_label=\"id\")\n",
    "\n",
    "print(f\"Done! Created manifest.csv with {len(manifest_df)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a8f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transmissions_dataset(Dataset):\n",
    "    def __init__(self,manifest_file, root_dir,matrix_size=50,pris_file='~/Downloads/transmissions/size_10/size_10_pris.csv'):\n",
    "        #print(\"Initializing dataset...\")\n",
    "        self.manifest = pd.read_csv(manifest_file,index_col=\"id\")\n",
    "        self.root_dir = root_dir\n",
    "        self.matrix_size = matrix_size\n",
    "        self.pris = np.loadtxt(os.path.expanduser(pris_file), delimiter=',')\n",
    "        #print(\"dataset_ready\")\n",
    "\n",
    "    def __len__(self):\n",
    "    #    print(\"Getting length of dataset...\")\n",
    "       # print(f\"Length: {len(self.manifest)}\")\n",
    "        return len(self.manifest)\n",
    "    def __getitem__(self, idx):\n",
    "        sample_info = self.manifest.iloc[idx]\n",
    "        conc = sample_info['concentration']\n",
    "        config = sample_info['config_id']\n",
    "        filepath = os.path.join(self.root_dir, sample_info['filepath'])\n",
    "    #    print(f\"Loading data from {filepath}...\")\n",
    "    #    print(f\"Concentration: {conc}, Config ID: {config}\")\n",
    "\n",
    "\n",
    "        #\"Get distance matrix\"\n",
    "        dist_mat = 0 *np.eye(self.matrix_size)\n",
    "        dist_mat[:conc,:conc] +=  distance_matrix(conc, config)\n",
    "        y = torch.tensor(dist_mat, dtype=torch.float32)\n",
    "\n",
    "        #\"Get transmission data\"\n",
    "        new_data = np.loadtxt(filepath, delimiter=',',skiprows=1)[:,1]\n",
    "        x = torch.tensor(np.clip(new_data, 0, self.pris), dtype=torch.float32)\n",
    "\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2822a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = transmissions_dataset(manifest_file='manifest.csv', root_dir=os.path.expanduser('~/Downloads/transmissions/size_10/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "940a8bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dataset[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "379d7635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0000, 49.0918, 12.3693,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [49.0918,  4.0000, 61.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [12.3693, 61.0000,  4.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=batch_size, num_workers=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c8903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b548a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7435805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class distance_matrix_nn(nn.Module):\n",
    "    def __init__(self, input_dim = 400, num_points = 50, hidden_dim = 256):\n",
    "        super(distance_matrix_nn, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = num_points * num_points\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, self.output_dim)\n",
    "        )\n",
    "\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        out = self.softplus(out)\n",
    "        D = out.view(-1,50,50)\n",
    "        return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa37247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(num_epochs, val_split, batch_size = 32):\n",
    "\n",
    "\n",
    "    device = \"cpu\"\n",
    "    model = distance_matrix_nn(400, num_points=50, hidden_dim=256)\n",
    "    optimizer = optim.SGD(model.parameters(),lr=0.01)\n",
    "        \n",
    "\n",
    "    n_val = int(len(dataset) * val_split)\n",
    "\n",
    "    n_train = len(dataset) - n_val\n",
    "\n",
    "    train_ds, val_ds = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, shuffle=True, batch_size = 32)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, shuffle=False, batch_size = 32)\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "\n",
    "    train_loss = []\n",
    "\n",
    "    val_loss = []\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_losdd = 0\n",
    "\n",
    "        for step, (xb,yb) in enumerate(train_loader):\n",
    "            xb,yb = xb.to(device),yb.to(device)\n",
    "\n",
    "            preds = model(xb)\n",
    "\n",
    "            loss = F.mse_loss(preds,yb)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_losdd += loss.item()\n",
    "\n",
    "        avg_loss = total_losdd/len(train_loader)\n",
    "\n",
    "        train_loss.append(avg_loss)\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"Epoch {epoch+1:03d} | Loss: {avg_loss:.6f}\")\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        val_loss_1 = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for xb,yb in val_loader:\n",
    "                preds = model(xb)\n",
    "                loss = F.mse_loss(preds,yb)\n",
    "                val_loss_1 += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss_1/ len(val_loader)\n",
    "\n",
    "        val_loss.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:03d} | Train Loss: {avg_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "\n",
    "        # -----------------\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(train_loss, label=\"Train Loss\")\n",
    "    plt.plot(val_loss, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    plt.title(\"Training & Validation Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return model, (train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b40c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss: 492.418042\n",
      "Epoch 001 | Train Loss: 492.418042 | Val Loss: 381.555322\n",
      "Epoch 002 | Loss: 381.559329\n",
      "Epoch 002 | Train Loss: 381.559329 | Val Loss: 381.464995\n",
      "Epoch 003 | Loss: 381.364018\n",
      "Epoch 003 | Train Loss: 381.364018 | Val Loss: 381.490178\n",
      "Epoch 004 | Loss: 381.446773\n",
      "Epoch 004 | Train Loss: 381.446773 | Val Loss: 381.450334\n",
      "Epoch 005 | Loss: 381.287907\n",
      "Epoch 005 | Train Loss: 381.287907 | Val Loss: 381.462051\n",
      "Epoch 006 | Loss: 381.297356\n",
      "Epoch 006 | Train Loss: 381.297356 | Val Loss: 381.446416\n",
      "Epoch 007 | Loss: 381.348607\n",
      "Epoch 007 | Train Loss: 381.348607 | Val Loss: 381.514298\n",
      "Epoch 008 | Loss: 381.331386\n",
      "Epoch 008 | Train Loss: 381.331386 | Val Loss: 381.466510\n",
      "Epoch 009 | Loss: 381.292285\n",
      "Epoch 009 | Train Loss: 381.292285 | Val Loss: 381.506732\n",
      "Epoch 010 | Loss: 381.291807\n",
      "Epoch 010 | Train Loss: 381.291807 | Val Loss: 381.517176\n",
      "Epoch 011 | Loss: 381.274743\n",
      "Epoch 011 | Train Loss: 381.274743 | Val Loss: 381.495868\n",
      "Epoch 012 | Loss: 381.251203\n",
      "Epoch 012 | Train Loss: 381.251203 | Val Loss: 381.459995\n",
      "Epoch 013 | Loss: 381.220128\n",
      "Epoch 013 | Train Loss: 381.220128 | Val Loss: 381.477817\n",
      "Epoch 014 | Loss: 381.219046\n",
      "Epoch 014 | Train Loss: 381.219046 | Val Loss: 381.473446\n",
      "Epoch 015 | Loss: 381.220195\n",
      "Epoch 015 | Train Loss: 381.220195 | Val Loss: 381.452338\n",
      "Epoch 016 | Loss: 381.183414\n",
      "Epoch 016 | Train Loss: 381.183414 | Val Loss: 381.455815\n",
      "Epoch 017 | Loss: 381.163426\n",
      "Epoch 017 | Train Loss: 381.163426 | Val Loss: 381.454099\n"
     ]
    }
   ],
   "source": [
    "trained_model = training_model(100,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feded47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932ae98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e697497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offdiag_mse(pred, target):\n",
    "    # pred, target: (B, N, N)\n",
    "    N = pred.size(-1)\n",
    "    eye = torch.eye(N, device=pred.device).bool()\n",
    "    mask = ~eye  # off-diagonal True\n",
    "    diff = pred - target\n",
    "    diff = diff[:, mask]\n",
    "    return (diff ** 2).mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        D = model(x)\n",
    "        loss = offdiag_mse(D, y)\n",
    "        losses.append(loss.item())\n",
    "    return sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = distance_matrix_nn(input_dim=input_dim, num_points=num_points, hidden_dim=hidden_dim).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for a, b in train_loader:\n",
    "        a, b = a.to(device), b.to(device)\n",
    "        \n",
    "        D = model(a)\n",
    "        loss = offdiag_mse(D, b)\n",
    "        \n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # safe training\n",
    "        opt.step()\n",
    "\n",
    "        running += loss.item() * a.size(0)\n",
    "\n",
    "    train_loss = running / len(train_loader.dataset)\n",
    "    val_loss   = evaluate(model, val_loader, device)\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        torch.save(model.state_dict(), \"best_distance_model.pt\")\n",
    "    print(f\"Epoch {epoch:02d} | train {train_loss:.4f} | val {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        D = model(x)\n",
    "        loss = offdiag_mse(D, y)\n",
    "        losses.append(loss.item())\n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1748544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best weights (optional)\n",
    "#model.load_state_dict(torch.load(\"best_distance_model.pt\", map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "x_sample, y_true = next(iter(val_loader))\n",
    "x_sample = x_sample.to(\"cpu\")\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_sample)  # (B, N, N)\n",
    "\n",
    "print(\"Pred shape:\", y_pred.shape)\n",
    "print(\"Example pred D[0]:\\n\", y_pred[0].cpu())\n",
    "print(\"Example true D[0]:\\n\", y_true[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cfaeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287c25f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa5039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = y_pred[0] - y_true[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33fe395",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692bc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Suppose y_pred, y_true are tensors of shape (B, 50, 50)\n",
    "diff = y_pred[0] - y_true[0]    # first sample\n",
    "diff = diff.detach().cpu().numpy()  # convert to NumPy if on GPU\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(diff, cmap='bwr', interpolation='nearest')\n",
    "plt.colorbar(label='Prediction error')\n",
    "plt.title(\"Difference: Predicted - True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd2c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max error:\", np.max(diff))\n",
    "print(\"Min error:\", np.min(diff))\n",
    "print(\"Mean absolute error:\", np.mean(np.abs(diff)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92629d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
